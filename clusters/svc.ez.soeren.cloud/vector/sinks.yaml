---
transforms:
  # Parse and enrich journald logs
  k8s_parser:
    type: "remap"
    inputs: ["k8s"]
    source: |
      .dc = get_env_var("DC") ?? ""
      .cluster = get_env_var("CLUSTER") ?? ""
      #.app_name = replace!(to_string!(.unit_name) || "unknown", r'\.(service|timer|socket)', "")

      if exists(.message) {
        message_str = string(.message) ?? ""

        # Try JSON first
        json_result = parse_json(message_str) ?? {}
        if exists(json_result.level) && is_string(json_result.level) {
          .log_level = downcase!(json_result.level)
        } else {
          # Comprehensive regex for common log level patterns
          level_match = parse_regex(message_str, r'(?i)(?:\[|<|\(|^|\s|level[=:]\s*|severity[=:]\s*|\|)(?P<level>info|error|warn|warning|debug|trace|fatal|critical)(?:\]|>|\)|[:\s]|\||$)') ?? {}

          if exists(level_match.level) {
            found_level = downcase!(level_match.level)

            # Normalize variations
            .log_level = found_level
          }
        }
      }


sinks:
  prom_exporter:
    type: "prometheus_exporter"
    inputs: ["host_metrics", "internal_metrics"]
    address: "0.0.0.0:9090"

  vlogs:
    inputs: ["k8s_parser"]
    type: "elasticsearch"
    endpoints:
      - https://logs.rs.soeren.cloud/insert/elasticsearch/
    api_version: v8
    compression: gzip
    healthcheck:
      enabled: false
    query:
      _msg_field: message
      _time_field: timestamp
      _stream_fields: kubernetes.pod_node_name,kubernetes.pod_namespace,kubernetes.pod_name,kubernetes.container_name,dc,cluster
